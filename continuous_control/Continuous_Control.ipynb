{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, D3PG agent will be implemented and tested on the Reacher Unity Environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='C:\\\\Users\\\\anindex\\\\Desktop\\\\Reacher_Windows_x86_64_20\\\\Reacher_Windows_x86_64\\\\Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with ength: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with ength: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training DDPG agent\n",
    "\n",
    "The implementation for DDPG agent is imported from this repository subfolder `agents/` as a library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#uncomment the following line if import failed\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__name__), '..')))\n",
    "\n",
    "from agents.agents import DDPGAgent\n",
    "\n",
    "agent = DDPGAgent(state_size, action_size, random_seed=0, num_agents=num_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading checkpoint if the file exists\n",
    "\n",
    "if os.path.isfile('actor.pth') and os.path.isfile('actor.pth'):\n",
    "    agent.actor_local.load_state_dict(torch.load('actor.pth'))\n",
    "    agent.actor_target.load_state_dict(torch.load('actor.pth'))\n",
    "    agent.critic_local.load_state_dict(torch.load('critic.pth'))\n",
    "    agent.critic_target.load_state_dict(torch.load('critic.pth'))\n",
    "    print(\"Loaded previous trained DDPG agent!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-10fcc4cc1972>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ddpg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-10fcc4cc1972>\u001b[0m in \u001b[0;36mtrain_ddpg\u001b[1;34m(n_episodes, max_t, print_every, save_every)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_agents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mstates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\deepRL-projects\\agents\\agents.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m  \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_UPDATES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscrete_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\deepRL-projects\\agents\\agents.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, experiences, gamma)\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[1;31m# ----------------------- update target networks ----------------------- #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_local\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_local\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTAU\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msoft_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\deepRL-projects\\agents\\agents.py\u001b[0m in \u001b[0;36msoft_update\u001b[1;34m(self, local_model, target_model, tau)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \"\"\"\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_param\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[0mtarget_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlocal_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtarget_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_ddpg(n_episodes=2000, max_t=1000, print_every=100, save_every=500):\n",
    "    \"\"\"Distributional DDPG (D3PG)\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "    \"\"\"\n",
    "    scores = []                                # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=print_every)  # last print_every scores\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        agent.reset()\n",
    "        \n",
    "        states = env_info.vector_observations\n",
    "        current_scores = np.zeros(num_agents)\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            \n",
    "            next_states = env_info.vector_observations  \n",
    "            rewards = env_info.rewards                \n",
    "            dones = env_info.local_done\n",
    "            current_scores += env_info.rewards  \n",
    "            \n",
    "            for i in range(num_agents):\n",
    "                agent.step(states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "                \n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        avg_score = np.mean(current_scores)\n",
    "        scores_window.append(avg_score)       # save most recent score\n",
    "        scores.append(avg_score)              # save most recent score\n",
    "\n",
    "        mean_score = np.mean(scores_window)\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, mean_score, avg_score))\n",
    "        if mean_score >= 33.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}, saving models!'.format(i_episode, mean_score))\n",
    "            torch.save(agent.actor_local.state_dict(), 'actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'critic.pth')\n",
    "    return scores\n",
    "\n",
    "scores = train_ddpg(n_episodes=200, print_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell for saving scores and Q network state_dict\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('DDPG_control_scores', 'wb') as fp:\n",
    "    pickle.dump(scores, fp)\n",
    "    \n",
    "torch.save(agent.actor_local.state_dict(), 'actor.pth')\n",
    "torch.save(agent.critic_local.state_dict(), 'critic.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate the agent\n",
    "\n",
    "We will then observe the trained behavior of the DDPG agent ands finally record the total average score of 20 agents. This cell will load the saved model and test the model on the env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 28.522499362472445\n"
     ]
    }
   ],
   "source": [
    "agent = DDPGAgent(state_size, action_size, random_seed=0, num_agents=num_agents)\n",
    "agent.actor_local.load_state_dict(torch.load('actor_v1.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('critic_v1.pth'))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = agent.act(states)                        # select an action (for each agent)\n",
    "\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
